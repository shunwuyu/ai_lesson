![](https://www.nowcoder.com/exam/interview/93698446/test?paperId=62119359&order=0)


- R1 和 V3的区别是什么？
  - DeepSeek-V3 指令型模型
    提示词依赖程度高、提示词是否专业会直接影响输出结果，快速响应和多任务处理。
  -  DeepSeek-R1 推理型模型 提示词依赖程度弱， 只要表达清楚要求、任务和目的，R1会揣摩提示词背后你要什么。设计复杂的逻辑推理或需要深度思考。


- 什么是大语言模型（LLM）？

  大语言模型（LLM, Large Language Model）是一类用来处理人类语言的人工智能模型。它们通常基于神经网络，尤其是Transformer架构，通过在海量文本数据上进行训练，学会了如何“理解”和“生成”自然语言。

  - 什么是深度学习？
  给llm很多猫的照片，它会自己总结“猫长什么样”，之后看到新照片就能判断是不是猫。
  用很多例子自己“摸索规律”，像人类大脑一样越学越聪明的技术。

  - 基于神经网络
  一种模仿人脑神经元连接方式的数学模型，是深度学习的基础。

  - Transformer：目前最主流的神经网络结构，擅长处理序列数据（比如文本）。

- LLM是怎么工作的？
  LLM的核心任务有两个：理解和生成。
  理解：模型能“看懂”输入的文本，比如判断一句话的意思、提取关键信息等。
  生成：模型能“写出”新的文本，比如自动补全、写作文、翻译、对话等。

- LLM的训练过程
  LLM之所以“聪明”，是因为它们在大量的文本数据上进行了训练。训练的过程可以简单理解为：
“让模型不断猜下一个词是什么，猜对了就奖励，猜错了就纠正。”

  就像小朋友学说话，听得多了、练得多了，自然就会说了。

- LLM的结构简图
  ![](https://uploadfiles.nowcoder.com/images/20250627/0_1751023407444/694D62125AAF6C6463BA63AC3F3192DD)

- LLM的应用场景
  - 聊天机器人：如ChatGPT、文心一言等
  - 智能写作：自动生成新闻、故事、代码等
  - 搜索与问答：根据问题给出精准答案
  - 翻译：多语言互译

- LLM的优势与挑战
  - 优势
    能处理复杂的语言任务
    适应性强，能迁移到多种应用场景
    不断进步，规模越大能力越强

  - 挑战
    需要大量数据和算力
    有时会“胡说八道”（幻觉）
    可能存在偏见和安全风险