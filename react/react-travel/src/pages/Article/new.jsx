import React, { useState, useRef } from 'react';
import styles from './new.module.css';
import {  
  speechToText
} from '../../llm/index'
export default function NewArticle() {
  const [title, setTitle] = useState('');
  const [content, setContent] = useState('');
  const [isRecording, setIsRecording] = useState(false);
  const mediaRecorderRef = useRef(null);
  const chunksRef = useRef([]);

  const handleStartRecording = async () => {
    try {
      // è¯·æ±‚è·å–ç”¨æˆ·çš„éº¦å…‹é£æƒé™å¹¶è·å–åª’ä½“æµ (MediaStream)
      // è¿™é‡Œåªè¯·æ±‚éŸ³é¢‘ (audio: true)ï¼Œä¸è¯·æ±‚è§†é¢‘
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });

      // åˆ›å»ºä¸€ä¸ª MediaRecorder å®ä¾‹ï¼Œç”¨äºå½•åˆ¶ä¸Šé¢è·å–åˆ°çš„åª’ä½“æµ
      // å°†å®ä¾‹å­˜å‚¨åœ¨ mediaRecorderRef çš„ current å±æ€§ä¸­ï¼Œä¾¿äºåç»­å¼•ç”¨å’Œæ§åˆ¶ï¼ˆå¦‚å¼€å§‹ã€åœæ­¢ï¼‰
      mediaRecorderRef.current = new MediaRecorder(stream);

      // åˆå§‹åŒ–ä¸€ä¸ªç©ºæ•°ç»„ï¼Œç”¨äºå­˜æ”¾å½•åˆ¶è¿‡ç¨‹ä¸­äº§ç”Ÿçš„æ•°æ®ç‰‡æ®µ (chunks)
      // å°†æ•°ç»„å­˜å‚¨åœ¨ chunksRef çš„ current å±æ€§ä¸­ï¼Œç¡®ä¿åœ¨ç»„ä»¶ä¸åŒæ¸²æŸ“é—´èƒ½æŒä¹…å¼•ç”¨å’Œä¿®æ”¹åŒä¸€ä¸ªæ•°ç»„
      chunksRef.current = [];

    // ä¸º MediaRecorder å®ä¾‹è®¾ç½® 'ondataavailable' äº‹ä»¶ç›‘å¬å™¨
    // å½“ MediaRecorder åœæ­¢å½•åˆ¶æˆ–è°ƒç”¨ requestData() æ–¹æ³•æ—¶ï¼Œä¼šè§¦å‘æ­¤äº‹ä»¶ï¼Œå¹¶å°†å½•åˆ¶çš„æ•°æ®ä½œä¸º Blob å¯¹è±¡ä¼ é€’
    mediaRecorderRef.current.ondataavailable = (e) => {
      // æ£€æŸ¥äº‹ä»¶ä¼ é€’è¿‡æ¥çš„æ•°æ® (e.data) æ˜¯å¦æœ‰å®é™…å†…å®¹ï¼ˆå¤§å°å¤§äº0ï¼‰
      // é˜²æ­¢å°†ç©ºçš„ Blob æ¨å…¥æ•°ç»„
      if (e.data.size > 0) {
        // å¦‚æœæ•°æ®æœ‰æ•ˆï¼Œå°†å…¶æ¨å…¥ä¹‹å‰åˆå§‹åŒ–çš„ chunksRef.current æ•°ç»„ä¸­
        // è¿™äº›æ•°æ®ç‰‡æ®µå°†åœ¨åç»­è¢«åˆå¹¶æˆå®Œæ•´çš„éŸ³é¢‘æ–‡ä»¶
        chunksRef.current.push(e.data);
      }
    };

      mediaRecorderRef.current.onstop = async () => {
        const blob = new Blob(chunksRef.current, { type: 'audio/webm' });
        // console.log(blob, '/////');
        const base64Audio = await blobToBase64(blob);
        console.log(base64Audio, '????')
        const transcript = await transcribeAudio(base64Audio);
        console.log(transcript);
        setContent((prev) => prev + '\n' + transcript);
      };

      mediaRecorderRef.current.start();
      setIsRecording(true);
    } catch (err) {
      console.error('å½•éŸ³å¤±è´¥:', err);
    }
  };

  const handleStopRecording = () => {
    mediaRecorderRef.current?.stop();
    setIsRecording(false);
  };

  const blobToBase64 = (blob) => {
    return new Promise((resolve) => {
      const reader = new FileReader();
      reader.onloadend = () => resolve(reader.result.split(',')[1]); // åªå– base64 æ•°æ®éƒ¨åˆ†
      reader.readAsDataURL(blob);
    });
  };

  const transcribeAudio = async (base64Audio) => {
    try  {
      const text = await speechToText(base64Audio);
      // console.log(text, '????')
      return text;
    } catch(err) {
      return ""
    }
    // try {
    //   const response = await fetch('https://api.openai.com/v1/audio/transcriptions', {
    //     method: 'POST',
    //     headers: {
    //       'Authorization': 'Bearer YOUR_OPENAI_API_KEY',
    //     },
    //     body: createFormData(base64Audio),
    //   });
    //   const data = await response.json();
    //   return data.text || '';
    // } catch (err) {
    //   console.error('è½¬æ–‡å­—å¤±è´¥:', err);
    //   return '';
    // }
  };

  

  const handleSaveDraft = () => {
    console.log('ä¿å­˜è‰ç¨¿:', { title, content });
    alert('è‰ç¨¿å·²ä¿å­˜ï¼');
  };

  const handlePublish = () => {
    if (!title.trim() || !content.trim()) {
      alert('æ ‡é¢˜å’Œå†…å®¹ä¸èƒ½ä¸ºç©ºï¼');
      return;
    }
    console.log('å‘å¸ƒæ–‡ç« :', { title, content });
    alert('æ–‡ç« å·²å‘å¸ƒï¼');
  };

  return (
    <div className={styles.container}>
      <h2>å‘è¡¨æ–‡ç« </h2>
      <input
        className={styles.input}
        placeholder="è¯·è¾“å…¥æ ‡é¢˜"
        value={title}
        onChange={(e) => setTitle(e.target.value)}
      />
      <div className={styles.textareaWrapper}>
        <textarea
          className={`${styles.input} ${styles.textarea}`}
          placeholder="è¯·è¾“å…¥å†…å®¹"
          value={content}
          onChange={(e) => setContent(e.target.value)}
        />
        <button
          className={styles.micButton}
          onMouseDown={handleStartRecording}
          onMouseUp={handleStopRecording}
          title="æŒ‰ä½å½•éŸ³"
        >
          ğŸ¤
        </button>
      </div>
      <div className={styles.buttonGroup}>
        <button className={`${styles.button} ${styles.save}`} onClick={handleSaveDraft}>
          ä¿å­˜è‰ç¨¿
        </button>
        <button className={`${styles.button} ${styles.publish}`} onClick={handlePublish}>
          å‘å¸ƒ
        </button>
      </div>
    </div>
  );
}
